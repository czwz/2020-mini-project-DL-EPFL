{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input = train_input.sub_(mean).div_(std)\n",
    "test_input = test_input.sub_(mean).div_(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        # The number of params:\n",
    "        # conv1: 32 * (2 * 3 * 3 + 1) = 608\n",
    "        # conv2: 64 * (32 * 3 * 3 + 1) = 18,496\n",
    "        # fc1: (256 + 1) * 200 = 51,400\n",
    "        # fc2: (200 + 1) * 2 = 402\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    eta = 1e-2\n",
    "    optimizer = optim.SGD(model.parameters(), lr = eta)\n",
    "    nb_epochs = 25\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            optimizer.step()\n",
    "        print(e, sum_loss, loss.item())\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k] != predicted_classes[k]:\n",
    "                nb_errors += 1\n",
    "                \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 67.6786521077156 0.6805179119110107\n",
      "1 64.84696900844574 0.6585527658462524\n",
      "2 60.8485132753849 0.6247842311859131\n",
      "3 55.65058037638664 0.6004491448402405\n",
      "4 51.15196964144707 0.589335560798645\n",
      "5 47.78808984160423 0.5765329599380493\n",
      "6 44.7143219858408 0.5606686472892761\n",
      "7 41.68522794544697 0.542558491230011\n",
      "8 38.71396865695715 0.5174574851989746\n",
      "9 35.90190816670656 0.4904783368110657\n",
      "10 33.2814721390605 0.45714932680130005\n",
      "11 30.735079683363438 0.4257314205169678\n",
      "12 28.2323512211442 0.38853901624679565\n",
      "13 25.69994755089283 0.353310763835907\n",
      "14 23.130427099764347 0.3111879527568817\n",
      "15 20.49694600701332 0.2673245072364807\n",
      "16 17.913814686238766 0.22689025104045868\n",
      "17 15.476673144847155 0.19381263852119446\n",
      "18 13.122067553922534 0.15925191342830658\n",
      "19 10.846822110936046 0.12692096829414368\n",
      "20 8.666893860325217 0.09930717945098877\n",
      "21 6.815945664420724 0.08093750476837158\n",
      "22 5.340742407366633 0.06476687639951706\n",
      "23 4.265223665162921 0.054555557668209076\n",
      "24 3.412018136586994 0.044531241059303284\n",
      "test error of Net 16.80% 168/1000\n"
     ]
    }
   ],
   "source": [
    "model = Net(200)\n",
    "mini_batch_size = 10\n",
    "\n",
    "train_model(model, train_input, train_target, mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "print('test error of Net {:0.2f}% {:d}/{:d}'\\\n",
    "      .format((100 * nb_test_errors) / test_input.size(0), nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with secondary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        # The number of params:\n",
    "        # conv1: 32 * (2 * 3 * 3 + 1) = 608\n",
    "        # conv2: 64 * (32 * 3 * 3 + 1) = 18,496\n",
    "        # fc1: (256 + 1) * 200 = 51,400\n",
    "        # fc2: (200 + 1) * 2 = 402\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6],\n",
       "        [9, 3],\n",
       "        [2, 8],\n",
       "        ...,\n",
       "        [6, 5],\n",
       "        [2, 6],\n",
       "        [5, 2]])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes, mini_batch_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    eta = 1e-2\n",
    "    optimizer = optim.SGD(model.parameters(), lr = eta)\n",
    "    nb_epochs = 25\n",
    "    lambda_l2 = 1e-3\n",
    "    lambda_dif = 1e-2\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            for p in model.parameters():\n",
    "                loss += lambda_l2 * p.pow(2).sum()\n",
    "            loss += \n",
    "            \n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(e, sum_loss, loss.item())\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k] != predicted_classes[k]:\n",
    "                nb_errors += 1\n",
    "                \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 77.71205252408981 0.7981922626495361\n",
      "1 75.2626336812973 0.7867611050605774\n",
      "2 72.00800466537476 0.7636763453483582\n",
      "3 67.23345014452934 0.739741861820221\n",
      "4 62.08496016263962 0.7242040038108826\n",
      "5 57.79992687702179 0.7162256836891174\n",
      "6 54.226865351200104 0.7041693329811096\n",
      "7 51.12853318452835 0.6902925372123718\n",
      "8 48.222820833325386 0.678102433681488\n",
      "9 45.53885594010353 0.6560991406440735\n",
      "10 42.98359262943268 0.6288289427757263\n",
      "11 40.37042357027531 0.5963085889816284\n",
      "12 37.89741112291813 0.5597342848777771\n",
      "13 35.393269032239914 0.5280466079711914\n",
      "14 33.00294107198715 0.4892234802246094\n",
      "15 30.49362015724182 0.44699838757514954\n",
      "16 28.146579667925835 0.40244346857070923\n",
      "17 25.764848053455353 0.35953861474990845\n",
      "18 23.5286066532135 0.3182789981365204\n",
      "19 21.309089943766594 0.2768385708332062\n",
      "20 19.436357460916042 0.23924520611763\n",
      "21 17.692589186131954 0.20404361188411713\n",
      "22 16.371249094605446 0.1814272105693817\n",
      "23 15.337117664515972 0.1671266108751297\n",
      "24 14.527177058160305 0.15548457205295563\n",
      "test error of Net 17.40% 174/1000\n"
     ]
    }
   ],
   "source": [
    "model = Net(200)\n",
    "mini_batch_size = 10\n",
    "\n",
    "train_model(model, train_input, train_target, mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "print('test error of Net {:0.2f}% {:d}/{:d}'\\\n",
    "      .format((100 * nb_test_errors) / test_input.size(0), nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
